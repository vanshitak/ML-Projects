{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPOm7nmvX1MK3rKgE40ZoCx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanshitak/ML-Projects/blob/main/SRS_usecase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPOct5iM0JIU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28ce0acd-5f1f-4602-acf7-aa5f81eb2339"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/2.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.0 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (1.10.13)\n",
            "Collecting openai_function_call\n",
            "  Downloading openai_function_call-0.2.6-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.2-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.66-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.5.0)\n",
            "Collecting openai<0.28.0,>=0.27.8 (from openai_function_call)\n",
            "  Downloading openai-0.27.10-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic)\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic)\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.6.1 (from pydantic)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<0.28.0,>=0.27.8->openai_function_call) (4.66.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, annotated-types, typing-inspect, pydantic-core, jsonpatch, pydantic, openai, dataclasses-json, openai_function_call, langsmith, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed annotated-types-0.6.0 dataclasses-json-0.6.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.340 langsmith-0.0.66 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-0.27.10 openai_function_call-0.2.6 pydantic-2.5.2 pydantic-core-2.14.5 typing-extensions-4.8.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install langchain pydantic openai_function_call"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai cohere tiktoken"
      ],
      "metadata": {
        "id": "puDli7-1lr2l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70aae69-75ea-4661-fd21-01a04aa7332d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.10)\n",
            "Collecting cohere\n",
            "  Downloading cohere-4.36-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m975.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Installing collected packages: fastavro, backoff, tiktoken, cohere\n",
            "Successfully installed backoff-2.2.1 cohere-4.36 fastavro-1.8.2 tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
        "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
        "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "from typing import List, Dict, Optional\n",
        "import openai\n",
        "from openai_function_call import OpenAISchema"
      ],
      "metadata": {
        "id": "60cI-Das0OLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip show openai"
      ],
      "metadata": {
        "id": "zDE_5bQspJyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(str(openai.__all__))"
      ],
      "metadata": {
        "id": "ZMJoiGAgscpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apikey = \"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\" #Vanshita's api key\n",
        "openai.api_key = apikey"
      ],
      "metadata": {
        "id": "ikZVrmYxe5Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining single use case as JSON"
      ],
      "metadata": {
        "id": "ZczQBIx8ktSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UseCaseFlow(BaseModel):\n",
        "    \"\"\"This class represents the different workflows for the use case\"\"\"\n",
        "    #Type: str = Field(...,description=\"Use 'Basic' for the main/typical flow, 'Alternate' for other possible/alternate flows, and 'Exceptional' for exception handling flows.\")\n",
        "    Trigger: str = Field(...,description=\"Describe what initiates or leads to this flow.\")\n",
        "    Steps: List[str] = Field(...,description=\"Each step includes a step number and the action to be performed.\")\n",
        "\n",
        "class DataField(BaseModel):\n",
        "    \"\"\"Complete information about a data field required in a usecase\"\"\"\n",
        "    Label: str = Field(...,description=\"Name of the data field\")\n",
        "    Type: str = Field(...,description=\"Data type of the field\")\n",
        "    Required: bool = Field(...,description=\"True if it is mandatory\")\n",
        "\n",
        "class UseCase(BaseModel):\n",
        "    \"\"\"This class contains a complete and detailed use case\"\"\"\n",
        "    #ID: str = Field(...,description=\"use case id\")\n",
        "    Title: str = Field(...,description=\"Title of the Use case\")\n",
        "    PrimaryUsage: str = Field(...,description=\"Description of the use case\")\n",
        "    Actors: List[str]\n",
        "    Preconditions: List[str]\n",
        "    MainFlow: UseCaseFlow = Field(...,description=\"Describes the main flow\")\n",
        "    AlternateFlow : UseCaseFlow = Field(...,description=\"Describes the alternate flow\")\n",
        "    ExceptionalFlow : UseCaseFlow = Field(...,description=\"Describes the flow in case of exceptions\")\n",
        "    BusinessRules : List[str] = Field(...,description=\"List of business rules or validations of the use case\")\n",
        "    Postconditions: List[str]\n",
        "    Assumptions: List[str]\n",
        "    Issues: List[str] = Field(description=\"potential challenges that may arise during execution\")\n",
        "    DataFields : List[DataField] = Field(...,description=\"List of data fields or variables associated with the use case\")\n"
      ],
      "metadata": {
        "id": "SVkD2lJX0OHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_usecase = convert_pydantic_to_openai_function(UseCase)"
      ],
      "metadata": {
        "id": "5HlmI7zhC5CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(openai_api_key=apikey,temperature=0.5,max_tokens=1000)"
      ],
      "metadata": {
        "id": "pKdOMbrpDfbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_function = model.bind(functions=[create_usecase], function_call={\"name\":\"UseCase\"})"
      ],
      "metadata": {
        "id": "Z14yHj7Klb0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert SRS writer who writes detailed usecases\"),\n",
        "    (\"user\", \"\"\"Your task is to write the following use case of the SRS for a {application} application to be used in {industry} industry-\n",
        "    {usecase_title} - {usecase_desc}\n",
        "    Make sure it is relevant to {region} context. Use a formal tone.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "QQkSPQ0wETLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model_with_function | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "8rgJoiaLzvNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input1 = {\"application\":\"HRMS\",\n",
        "                \"industry\":\"IT\",\n",
        "                \"uc_title\":\"Leave Management\",\n",
        "                \"uc_description\":\"Allow employees to apply for leaves, track leave balances, and manage leave approvals as per company policies.\",\n",
        "                \"region\":\"Indian\"}\n",
        "\n",
        "sample_input2 = {\"application\":\"HRMS\",\n",
        "                \"industry\":\"IT\",\n",
        "                \"uc_title\":\"Attendance tracking\",\n",
        "                \"uc_description\":\"Record and track employee attendance, including clock-in/out, late arrivals, early departures, and absenteeism.\",\n",
        "                \"region\":\"Indian\"}\n",
        "\n",
        "sample_input3 = {\"application\":\"HRMS\",\n",
        "                \"industry\":\"IT\",\n",
        "                \"uc_title\":\"Payroll Management\",\n",
        "                \"uc_description\":\"Manage employee salaries, deductions, tax calculations, and generate payslips as per statutory requirements.\",\n",
        "                \"region\":\"Indian\"}"
      ],
      "metadata": {
        "id": "YLuY68kYhEBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = chain.invoke(sample_input1)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ZXtYFFz-mD",
        "outputId": "2d18a640-bfa0-4dc7-c0ff-16f3628f099e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Title': 'Product Catalog', 'Description': 'The Product Catalog use case allows users to view a comprehensive catalog of fashion products available in the e-commerce application. The catalog provides details such as price, size, color, fabric, and other relevant information. This use case is specifically designed for the Indian fashion industry.', 'Actors': ['User'], 'Preconditions': ['The user has logged into the e-commerce application.', 'The user has access to the internet.'], 'MainFlow': [{'Trigger': \"User selects the 'Product Catalog' option from the application menu.\", 'Steps': ['The system retrieves the list of fashion products from the database.', 'The system displays the list of fashion products in a grid or list format.', 'For each product, the system displays the product image, name, price, and other relevant details.', 'The user can scroll through the catalog to view more products.', 'The user can filter the catalog based on various criteria such as price range, size, color, fabric, etc.', 'The user can sort the catalog based on price, popularity, or other relevant criteria.', 'The user can click on a product to view its detailed information.']}], 'AlternateFlow': [], 'ExceptionalFlow': [], 'BusinessRules': ['The catalog should only display fashion products relevant to the Indian market.', 'The catalog should be updated regularly to include new products and remove out-of-stock products.'], 'Postconditions': ['The user has viewed the product catalog.', 'The user can proceed to other actions such as adding products to the cart or making a purchase.'], 'Assumptions': ['The user has a basic understanding of using an e-commerce application.', 'The user has a device with a compatible operating system and internet connectivity.'], 'Issues': ['The catalog may take some time to load if there are a large number of products.', 'The catalog may not display properly if the user has a slow internet connection.'], 'DataFields': [{'Label': 'Product Image', 'Type': 'Image', 'Required': True}, {'Label': 'Product Name', 'Type': 'Text', 'Required': True}, {'Label': 'Price', 'Type': 'Number', 'Required': True}, {'Label': 'Size', 'Type': 'Text', 'Required': False}, {'Label': 'Color', 'Type': 'Text', 'Required': False}, {'Label': 'Fabric', 'Type': 'Text', 'Required': False}]}\n",
            "Tokens Used: 910\n",
            "\tPrompt Tokens: 310\n",
            "\tCompletion Tokens: 600\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0016649999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining sub usecase list"
      ],
      "metadata": {
        "id": "NHk1d_kppJgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_batch = [sample_input1, sample_input2, sample_input3]"
      ],
      "metadata": {
        "id": "mADk0xwrp306"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class each_sub_uc(BaseModel):\n",
        "    \"\"\"This class contains complete information about each sub-usecase\"\"\"\n",
        "    title : str = Field(...,description=\"Title of the sub-usecase\")\n",
        "    description : str = Field(...,description=\"Brief description of the sub-usecase\")\n",
        "\n",
        "class list_of_sub_uc(BaseModel):\n",
        "    \"\"\"This class contains a list of sub-usecases along with descriptions for the main use case\"\"\"\n",
        "    sub_uc_list : List[each_sub_uc] = Field(..., min_items=2, max_items=8)\n",
        "\n",
        "sub_usecase_list = convert_pydantic_to_openai_function(list_of_sub_uc)\n",
        "\n",
        "list_generator = model.bind(functions=[sub_usecase_list], function_call={\"name\":\"list_of_sub_uc\"})\n",
        "\n",
        "list_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert SRS writer\"),\n",
        "    (\"user\", \"\"\"Create a list of sub-use cases along with brief descriptions for the following main use case-\n",
        "    {uc_title}-{uc_description}\n",
        "    Context- This usecase is part of the functional requirements for {application} application to be used in {industry} industry in {region} region\n",
        "    \"\"\")\n",
        "])\n",
        "\n",
        "list_chain = list_prompt | list_generator | JsonOutputFunctionsParser()\n",
        "\n",
        "with get_openai_callback() as callback:\n",
        "    output = list_chain.batch(input_batch)\n",
        "    print(output, callback)\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "2YOJVWNlpIpD",
        "outputId": "18b7fa5a-4ca2-4728-ebe1-4e626f8f61b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'sub_uc_list': [{'title': 'Apply for leaves', 'description': 'Employees can submit leave requests specifying the leave type, duration, and reason.'}, {'title': 'Track leave balances', 'description': 'Employees can view their current leave balances, including annual leave, sick leave, and other types of leaves.'}, {'title': 'Manage leave approvals', 'description': 'Managers can review and approve or reject leave requests submitted by employees.'}, {'title': 'Enforce company leave policies', 'description': 'The system should enforce company-specific leave policies such as maximum leave duration, minimum notice period, and leave blackout periods.'}, {'title': 'Manage leave accruals', 'description': 'The system should automatically calculate and update leave accruals based on company policies and employee tenure.'}, {'title': 'Handle leave cancellations', 'description': 'Employees should be able to cancel leave requests if necessary, and the system should handle the cancellation process accordingly.'}, {'title': 'Generate leave reports', 'description': 'The system should provide reports on leave usage, balances, and trends for HR and management purposes.'}]}, {'sub_uc_list': [{'title': 'Clock-in/out', 'description': 'Allow employees to clock in and out of work to accurately track their attendance.'}, {'title': 'Late arrivals', 'description': 'Record and track instances when employees arrive late to work.'}, {'title': 'Early departures', 'description': 'Record and track instances when employees leave work earlier than scheduled.'}, {'title': 'Absenteeism', 'description': 'Track and monitor employee absences to identify patterns and address any issues.'}]}, {'sub_uc_list': [{'title': 'Manage employee salaries', 'description': 'This sub-use case allows the user to input and update employee salaries based on their job roles and experience levels.'}, {'title': 'Manage deductions', 'description': 'This sub-use case enables the user to define and manage various types of deductions such as taxes, insurance premiums, and loan repayments for each employee.'}, {'title': 'Calculate taxes', 'description': 'This sub-use case automates the calculation of taxes for each employee based on their salary, tax slabs, and applicable deductions.'}, {'title': 'Generate payslips', 'description': 'This sub-use case generates payslips for each employee, including details of their salary, deductions, taxes, and net pay, in compliance with statutory requirements.'}]}] Tokens Used: 1072\n",
            "\tPrompt Tokens: 472\n",
            "\tCompletion Tokens: 600\n",
            "Successful Requests: 3\n",
            "Total Cost (USD): $0.0019080000000000002\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-94338e0a85ee>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokens'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cost'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_cost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining a list of use cases"
      ],
      "metadata": {
        "id": "oH4leR8ikg8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class sub_usecase(BaseModel):\n",
        "    \"\"\"Title and brief description of each sub-usecase\"\"\"\n",
        "    ID : str = Field(...,description=\"Use Case ID\")\n",
        "    title : str = Field(...,description=\"Title of the sub-usecase\")\n",
        "    description : str = Field(...,description=\"Brief description of the sub-usecase\")\n",
        "\n",
        "class each_usecase(BaseModel):\n",
        "    \"\"\"An overall description of the main usecase along with a list of sub-usecases\"\"\"\n",
        "    main_usecase : str = Field(...,description=\"Title of the main usecase\")\n",
        "    sub_usecase_list : List[sub_usecase] = Field(...,min_items=1,max_items=5)\n",
        "\n",
        "class List_of_usecases(BaseModel):\n",
        "    \"\"\"This class contains a list of main usecases along with description of each\"\"\"\n",
        "    List_of_usecase : list[each_usecase] = Field(...,min_items=20)"
      ],
      "metadata": {
        "id": "WaNw00NWv2Nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "usecase_list = convert_pydantic_to_openai_function(List_of_usecases)"
      ],
      "metadata": {
        "id": "--H7LGD7z9E2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(usecase_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29YqLJXC4Nah",
        "outputId": "6233455d-e202-435c-a357-001fba369067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'List_of_usecases', 'description': 'This class contains a list of main usecases along with description of each', 'parameters': {'$defs': {'each_usecase': {'description': 'An overall description of the main usecase along with a list of sub-usecases', 'properties': {'main_usecase': {'description': 'Title of the main usecase', 'title': 'Main Usecase', 'type': 'string'}, 'sub_usecase_list': {'items': {'$ref': '#/$defs/sub_usecase'}, 'maxItems': 8, 'minItems': 1, 'title': 'Sub Usecase List', 'type': 'array'}}, 'required': ['main_usecase', 'sub_usecase_list'], 'title': 'each_usecase', 'type': 'object'}, 'sub_usecase': {'description': 'Title and brief description of each sub-usecase', 'properties': {'ID': {'description': 'Use Case ID', 'title': 'Id', 'type': 'string'}, 'title': {'description': 'Title of the sub-usecase', 'title': 'Title', 'type': 'string'}, 'description': {'description': 'Brief description of the sub-usecase', 'title': 'Description', 'type': 'string'}}, 'required': ['ID', 'title', 'description'], 'title': 'sub_usecase', 'type': 'object'}}, 'description': 'This class contains a list of main usecases along with description of each', 'properties': {'List_of_usecase': {'items': {'description': 'An overall description of the main usecase along with a list of sub-usecases', 'properties': {'main_usecase': {'description': 'Title of the main usecase', 'title': 'Main Usecase', 'type': 'string'}, 'sub_usecase_list': {'items': {'description': 'Title and brief description of each sub-usecase', 'properties': {'ID': {'description': 'Use Case ID', 'title': 'Id', 'type': 'string'}, 'title': {'description': 'Title of the sub-usecase', 'title': 'Title', 'type': 'string'}, 'description': {'description': 'Brief description of the sub-usecase', 'title': 'Description', 'type': 'string'}}, 'required': ['ID', 'title', 'description'], 'title': 'sub_usecase', 'type': 'object'}, 'maxItems': 8, 'minItems': 1, 'title': 'Sub Usecase List', 'type': 'array'}}, 'required': ['main_usecase', 'sub_usecase_list'], 'title': 'each_usecase', 'type': 'object'}, 'minItems': 20, 'title': 'List Of Usecase', 'type': 'array'}}, 'required': ['List_of_usecase'], 'title': 'List_of_usecases', 'type': 'object'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ChatOpenAI(model_name=\"gpt-3.5-turbo\", openai_api_key=apikey)"
      ],
      "metadata": {
        "id": "OemgfuYK4zxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_generator = model.bind(functions=[usecase_list], function_call={\"name\":\"List_of_usecases\"})"
      ],
      "metadata": {
        "id": "zY_jC7YH0NI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert SRS writer\"),\n",
        "    (\"user\", \"\"\"First create a list of 20 main use cases along with brief descriptions for a {application} application to be used in {industry} industry.\n",
        "    Then create sub-usecases with descriptions for each use case. Try to cover all the functional requirements through your response.\n",
        "    Make sure it is relevant to {region} context.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "vjGJwjO80ykx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_chain = list_prompt | list_generator | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "qNsriLet1Rl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input2 = {\n",
        "    \"application\":\"Crime and criminal tracking network\",\n",
        "    \"industry\":\"law enforcement\",\n",
        "    \"region\":\"indian\"\n",
        "}"
      ],
      "metadata": {
        "id": "cS_8Rw-Kkf53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = list_chain.invoke(sample_input2)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "cnQWn5xBoM3t",
        "outputId": "cba6a1bd-5ef5-4f88-c7bc-d9eff3bd3e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutputParserException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/openai_functions.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                         return json.loads(\n\u001b[0m\u001b[1;32m     99\u001b[0m                             \u001b[0mfunction_call\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"arguments\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0mkw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parse_constant'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_constant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 293 column 11 (char 11726)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-7f784fbac99d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mget_openai_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m                 input = step.invoke(\n\u001b[0m\u001b[1;32m   1203\u001b[0m                     \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                     \u001b[0;31m# mark each step as a child run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/output_parser.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m    172\u001b[0m     ) -> T:\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             return self._call_with_config(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 lambda inner_input: self.parse_result(\n\u001b[1;32m    176\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable/base.py\u001b[0m in \u001b[0;36m_call_with_config\u001b[0;34m(self, func, input, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         )\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             output = call_func_with_variable_args(\n\u001b[0m\u001b[1;32m    705\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/runnable/config.py\u001b[0m in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maccepts_run_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/schema/output_parser.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             return self._call_with_config(\n\u001b[0;32m--> 175\u001b[0;31m                 lambda inner_input: self.parse_result(\n\u001b[0m\u001b[1;32m    176\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mChatGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minner_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/output_parsers/openai_functions.py\u001b[0m in \u001b[0;36mparse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    100\u001b[0m                         )\n\u001b[1;32m    101\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                         raise OutputParserException(\n\u001b[0m\u001b[1;32m    103\u001b[0m                             \u001b[0;34mf\"Could not parse function call data: {exc}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m                         )\n",
            "\u001b[0;31mOutputParserException\u001b[0m: Could not parse function call data: Unterminated string starting at: line 293 column 11 (char 11726)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining executive summary"
      ],
      "metadata": {
        "id": "HFOTIcNpgfFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class executive_summary(BaseModel):\n",
        "    \"\"\"Summarize the text and identify the type of application and industry required by the user\"\"\"\n",
        "    summary : str = Field(...,description=\"Summary of text in professional tone\")\n",
        "    application : str = Field(...,description=\"Name of the application described by the user\")\n",
        "    industry : str = Field(...,description=\"Name of the industry that requires the application\")"
      ],
      "metadata": {
        "id": "dMvEMAKVrCo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exec_summary = convert_pydantic_to_openai_function(executive_summary)"
      ],
      "metadata": {
        "id": "fuKIqQETrZj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_generator = model.bind(functions=[exec_summary], function_call={\"name\":\"executive_summary\"})"
      ],
      "metadata": {
        "id": "skgQZDy5jGwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert SRS writer\"),\n",
        "    (\"user\", \"\"\"your task is to write the executive summary from the following text-\n",
        "    {input_text}\n",
        "    Identify the application described above and the industry it will be used in.\n",
        "    Use a formal tone.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "ZBconZS1jli8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_chain = summary_prompt | summary_generator | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "RPLFv4C7kyzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input03 = {\n",
        "    \"input_text\" : \"\"\n",
        "}"
      ],
      "metadata": {
        "id": "iIRLDJZyKiBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = list_chain.invoke(sample_input2)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "id": "yfAck8A8O30C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "JSONformer using pydantic"
      ],
      "metadata": {
        "id": "M01-K83ea038"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class form_field(BaseModel):\n",
        "    \"\"\"This class contains complete info of each form field\"\"\"\n",
        "    Label : str = Field(...,description=\"Name of form field\")\n",
        "    Type : str = Field(...,description=\"Type of form field\")\n",
        "    Required : bool = Field(...,description=\"True if it is required\")\n",
        "    Options : Optional[List[str]] = Field(description=\"Display options for the form field if needed\")\n",
        "\n",
        "class form_field_array(BaseModel):\n",
        "    \"\"\"This class contains a list of form fields along with its properties\"\"\"\n",
        "    form_field_list : List[form_field] = Field(...,min_items=10,max_items=20)\n",
        "\n",
        "form_maker = convert_pydantic_to_openai_function(form_field_array)\n",
        "\n",
        "form_generator = model.bind(functions=[form_maker], function_call={\"name\":\"form_field_array\"})"
      ],
      "metadata": {
        "id": "2K_GWbX7O9fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "form_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert form designer\"),\n",
        "    (\"user\", \"\"\"Your task is to return the information of the form fields required by the user-\n",
        "    user requirement- {form_name}\n",
        "    Make sure your response is relevant for indian region.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "UOoESljqiRkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "form_chain = form_prompt | form_generator | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "IVhRzMbcjzZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input04 = {\n",
        "    \"form_name\":\"school registration form\"\n",
        "}\n",
        "sample_input05 = {\n",
        "    \"form_name\":\"Resident Welfare Society (RWS) Election Nomination Form\"\n",
        "}"
      ],
      "metadata": {
        "id": "itcdlZ-Hkaet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = form_chain.invoke(sample_input05)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vU3rU-tflDQ4",
        "outputId": "e1f3cb5d-ea1b-434d-8250-230da8c7588d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'form_field_list': [{'Label': 'Full Name', 'Type': 'Text', 'Required': True, 'Options': []}, {'Label': 'Gender', 'Type': 'Dropdown', 'Required': True, 'Options': ['Male', 'Female', 'Other']}, {'Label': 'Date of Birth', 'Type': 'Date', 'Required': True, 'Options': []}, {'Label': 'Residential Address', 'Type': 'Text', 'Required': True, 'Options': []}, {'Label': 'Email', 'Type': 'Email', 'Required': True, 'Options': []}, {'Label': 'Mobile Number', 'Type': 'Text', 'Required': True, 'Options': []}, {'Label': 'Aadhaar Card Number', 'Type': 'Text', 'Required': True, 'Options': []}, {'Label': 'Nomination Category', 'Type': 'Dropdown', 'Required': True, 'Options': ['President', 'Vice President', 'Secretary', 'Treasurer', 'Member']}, {'Label': 'Upload Photo', 'Type': 'File', 'Required': True, 'Options': []}, {'Label': 'Upload Aadhaar Card', 'Type': 'File', 'Required': True, 'Options': []}]}\n",
            "Tokens Used: 477\n",
            "\tPrompt Tokens: 134\n",
            "\tCompletion Tokens: 343\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0008870000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Sections of SRS document"
      ],
      "metadata": {
        "id": "9LlupDNgwqlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class subsec(BaseModel):\n",
        "    \"\"\"details of each subsection with headings and its content\"\"\"\n",
        "    heading : str = Field(...,description=\"title of the subsection\")\n",
        "    content : List[str] = Field(...,description=\"content of the subsection in paragraphs\",)\n",
        "\n",
        "class section(BaseModel):\n",
        "    \"\"\"This class contains complete section details\"\"\"\n",
        "    title : str = Field(...,description=\"Title of the section\")\n",
        "    subsections : List[subsec] = Field(...,description=\"Title and description of subsections\",min_items=5)\n",
        "\n",
        "write_section = convert_pydantic_to_openai_function(section)\n",
        "\n",
        "section_generator = model.bind(functions=[write_section], function_call={\"name\":\"section\"})"
      ],
      "metadata": {
        "id": "tZN3Dyo05zJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "section_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert SRS writer.\"),\n",
        "    (\"user\", \"\"\"Your task is to write the {section} section inside the SRS for a {application} application to be used in {industry} industry.\n",
        "    Context- {context}\n",
        "    Ensure that the information is not solely dependent on the context provided. It should be relevant for {region} region.\n",
        "    Be clear and concise. Use a professional tone.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "gh41wuB2KDYE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "section_chain = section_prompt | section_generator | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "pgXThvJhMOpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input06 = {\n",
        "    \"section\":\"system architecture\",\n",
        "    \"application\":\"HRMS\",\n",
        "    \"industry\":\"IT\",\n",
        "    \"region\":\"Indian\",\n",
        "    \"context\":\"We are using AWS cloud server to store all data\"\n",
        "}"
      ],
      "metadata": {
        "id": "8gs2OdWTMf75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = section_chain.invoke(sample_input06)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5B2D2wxRSS8",
        "outputId": "8a2a7f82-4efa-4900-cd54-7c9ecacfff2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'title': 'System Architecture', 'subsections': [{'heading': 'Overview', 'content': ['The system architecture of the HRMS application is designed to provide a scalable and secure solution for managing human resources in the IT industry. The application is hosted on the AWS cloud server, ensuring high availability and reliability of the system.', 'The architecture follows a client-server model, where the client-side consists of web browsers or mobile devices, and the server-side consists of the application servers and the AWS cloud infrastructure.', 'The system architecture is designed to meet the requirements of the Indian region, taking into consideration the unique regulatory and compliance needs of the country.']}, {'heading': 'AWS Cloud Server', 'content': ['The HRMS application is hosted on the AWS cloud server, which provides a secure and scalable infrastructure for storing and processing data. The AWS cloud server is located in the Mumbai region, ensuring low-latency access for users in India.', 'The use of AWS cloud server allows for easy scalability of resources, enabling the application to handle a large number of users and data without compromising performance.', 'The AWS cloud server also provides built-in security features, such as encryption at rest and in transit, to protect the sensitive HR data from unauthorized access.', 'Regular backups of the data are performed to ensure data integrity and availability in case of any unforeseen events.']}, {'heading': 'Client-Side', 'content': ['The client-side of the HRMS application is accessible through web browsers or mobile devices. The web interface is designed to be user-friendly and responsive, providing an intuitive user experience.', 'The application is compatible with major web browsers, including Google Chrome, Mozilla Firefox, and Microsoft Edge, ensuring that users can access the application from their preferred browser.', 'Mobile applications are available for both Android and iOS platforms, allowing users to access the HRMS application on their smartphones and tablets.', 'The client-side communicates with the server-side through secure HTTPS protocols, ensuring the confidentiality and integrity of the data transmitted between the client and the server.']}, {'heading': 'Server-Side', 'content': ['The server-side of the HRMS application consists of multiple application servers hosted on the AWS cloud infrastructure. The application servers handle the processing of user requests and the storage and retrieval of data.', 'The server-side is built using a microservices architecture, where each microservice is responsible for a specific functionality of the HRMS application, such as employee management, attendance tracking, and payroll processing.', 'Each microservice is deployed as a separate containerized application, ensuring isolation and scalability of resources.', 'The server-side uses a secure RESTful API to communicate with the client-side, allowing for seamless integration and data exchange.', 'The server-side also includes a database server, which stores all the HR data. The database server is hosted on the AWS cloud infrastructure and is backed up regularly to prevent data loss.', 'The server-side implements access controls and authentication mechanisms to ensure that only authorized users can access and modify the HR data.']}, {'heading': 'Integration with External Systems', 'content': ['The HRMS application is designed to integrate with external systems commonly used in the IT industry, such as ERP systems, time and attendance systems, and payroll systems.', 'The integration is done through secure APIs and data exchange protocols, ensuring the seamless flow of information between the HRMS application and the external systems.', 'The integration allows for real-time synchronization of data, eliminating manual data entry and reducing errors.', 'The HRMS application also provides APIs for integration with third-party services, such as job portals and background verification services, to streamline the recruitment and onboarding process.']}]}\n",
            "Tokens Used: 962\n",
            "\tPrompt Tokens: 161\n",
            "\tCompletion Tokens: 801\n",
            "Successful Requests: 1\n",
            "Total Cost (USD): $0.0018435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Triples generation using pydantic class"
      ],
      "metadata": {
        "id": "DDf4UwjqhloF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Triples(Basemodel):\n",
        "    \"\"\"This class contains a singe triplet\"\"\"\n",
        "    Subject : str = Field(..., description=\" \")\n",
        "    Relation : str = Field(..., description=\" \")\n",
        "    Object : str = Field(..., description=\" \")\n",
        "\n",
        "class ListOfTriples(Basemodel):\n",
        "    \"\"\"This class contains a list of triplets\"\"\"\n",
        "    TripleStore = List[Triples] = Field(..., description=\" \")\n",
        "\n",
        "create_triples = convert_pydantic_to_openai_function(ListOfTriples)\n",
        "\n",
        "triple_generator = model.bind(functions=[create_triples], function_call={\"name\":\"ListOfTriples\"})"
      ],
      "metadata": {
        "id": "bdsHtKpChlPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triple_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a word class entity recognition and relation extraction algorithm\"),\n",
        "    (\"user\", \"\"\"Your task is to extract triples for creating a knowledge graph from the following text-\n",
        "    {text}\n",
        "    Give the response in the form of a JSON object.\n",
        "    \"\"\")\n",
        "])"
      ],
      "metadata": {
        "id": "5jwBMj6whlBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triple_chain = triple_prompt | triple_generator | JsonOutputFunctionsParser()"
      ],
      "metadata": {
        "id": "iiJCpF88nNMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_input07 = {\n",
        "    \"text\" : \"\"\n",
        "}"
      ],
      "metadata": {
        "id": "f7kRy5DknVa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with get_openai_callback() as callback:\n",
        "    output = triple_chain.invoke(sample_input07)\n",
        "    print(output)\n",
        "    print(callback)"
      ],
      "metadata": {
        "id": "qQeWblX1nchI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}